---
title: "Multi-Path Stepwise Selection Demonstration"
author: "Lijuan Wang, Evan Jerome, Kira Noordwijk"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
---

**GitHub Repository:** [R-4-Data-Science/finalprojectgroup12](https://github.com/R-4-Data-Science/finalprojectgroup12)

# Abstract

This HTML report demonstrates multi-path forward stepwise selection, stability estimation, plausible model selection, and test-set performance evaluation for both linear (Gaussian) and logistic (Binomial) regression. Enhanced analysis includes second-order terms, interactions, multiple Delta/tau exploration, Jaccard-based deduplication, and top model evaluation.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(finalprojectgroup12)
library(knitr)
library(mlbench)
library(dplyr)
set.seed(123)
```


# 1. Linear Regression Example (Gaussian)

```{r}
# Simulate Gaussian data
n <- 80
p <- 6
X <- matrix(rnorm(n*p), n, p)
colnames(X) <- paste0("x", 1:p)
beta <- c(1.5, -1, 0, 0, 0.8, 0)
y <- as.numeric(X %*% beta + rnorm(n))

# Multi-path forward selection
forest <- build_paths(x = X, y = y, family = "gaussian", K = 6, eps = 1e-6, delta = 1, L = 50)

# Show top 5 models by AIC
kable(head(forest$aic_by_model,5), caption="Top 5 linear models by AIC", format="html")

# Stability estimation
stab <- stability(x = X, y = y, B = 20, 
                  build_args = list(K = 6, eps = 1e-6, delta = 1, L = 50, family="gaussian"), 
                  verbose = TRUE)
stab_sorted <- sort(stab$pi, decreasing=TRUE)
kable(data.frame(variable=names(stab_sorted), stability=stab_sorted), caption="Variable Stability (Linear)", format="html")

# Plausible models
plaus <- plausible_models(forest, pi = stab$pi, Delta = 2, tau = 0.4)
kable(plaus, caption="Plausible linear models", format="html")

# Visualize stability
barplot(stab$pi, main="Variable Stability (Linear)", col="steelblue", las=2)
```


# 2. Breast Cancer Data: Logistic Regression (Binomial)

```{r}
# Load Wisconsin Breast Cancer dataset
data("BreastCancer")
bc <- na.omit(BreastCancer)

# Encode outcomes: malignant=1, benign=0
y <- ifelse(bc$Class=="malignant",1,0)

# Drop ID and Class columns, convert to numeric
X_base_raw <- bc[, setdiff(names(bc), c("Id","Class"))]
X_base_raw <- as.data.frame(lapply(X_base_raw, function(col) as.numeric(as.character(col))))

# Standardize predictors
X_base <- as.data.frame(scale(X_base_raw))
rownames(X_base) <- NULL
n <- nrow(X_base)
p_base <- ncol(X_base)

# Generate quadratic and interaction terms
X_quad <- X_base^2
colnames(X_quad) <- paste0(colnames(X_base), "^2")

num_int <- p_base*(p_base-1)/2
X_int <- matrix(NA_real_, nrow=n, ncol=num_int)
int_names <- character(num_int)
k <- 1
for (i in 1:(p_base-1)) {
  for (j in (i+1):p_base) {
    X_int[,k] <- X_base[,i]*X_base[,j]
    int_names[k] <- paste0(colnames(X_base)[i], ":", colnames(X_base)[j])
    k <- k + 1
  }
}
colnames(X_int) <- int_names

# Combine features
X <- cbind(X_base, X_quad, X_int)

# Train/Test split
train_frac <- 0.8
n_train <- floor(train_frac*n)
train_idx <- sample(seq_len(n), n_train)
X_train <- X[train_idx, ]
y_train <- y[train_idx]
X_test <- X[-train_idx, ]
y_test <- y[-train_idx]

# Standardize column names
colnames(X_train) <- make.names(colnames(X_train))
colnames(X_test) <- make.names(colnames(X_test))

# Multi-path forward selection
forest_bin <- suppressWarnings(
  build_paths(x = X_train, y = y_train, family = "binomial", K = 5, eps = 1e-6, delta = 1, L = 50, keep_fits=TRUE)
)

# Show top 5 AIC models
forest_bin$aic_by_model <- forest_bin$aic_by_model[order(forest_bin$aic_by_model$aic), ]
kable(head(forest_bin$aic_by_model,5), caption="Top 5 Logistic Models by AIC", format="html")

# Stability estimation
stab_bin <- suppressWarnings(
  stability(x = X_train, y = y_train, B = 50, resample = "bootstrap",
            build_args = list(family="binomial", K=5, eps=1e-6, delta=1, L=50, keep_fits=FALSE))
)
stab_bin_sorted <- sort(stab_bin$pi, decreasing=TRUE)
kable(data.frame(variable=names(stab_bin_sorted), stability=stab_bin_sorted),
      caption="Variable Stability (Binomial)", format="html")

# Visualize stability
barplot(stab_bin$pi, main="Variable Stability (Binomial)", col="salmon", las=2)

# Plausible models
plaus_bin_jaccard <- plausible_models(forest_bin, pi=stab_bin$pi, Delta=15, tau=0.25, jaccard_thresh=0.9)
if(nrow(plaus_bin_jaccard)==0){
  message("Warning: no plausible models selected. Try adjusting Delta/tau.")
}else{
  kable(plaus_bin_jaccard, caption = "Plausible Logistic Models after Jaccard Deduplication", format = "html")
}
```


# 3. Test-Set Performance Evaluation

```{r}
if(nrow(plaus_bin_jaccard) > 0){

  # Non-empty plausible models

  plaus_models <- lapply(plaus_bin_jaccard$vars, function(vars) make.names(vars))
  plaus_models <- Filter(function(v) length(v) > 0, plaus_models)

  perf_list <- lapply(plaus_models, function(vars) {
    common_vars <- intersect(vars, colnames(X_train))
    fit <- glm(as.formula(paste("y ~", paste(common_vars, collapse="+"))),
               data=data.frame(y=y_train, X_train[,common_vars,drop=FALSE]), family=binomial())
    
    X_test_sub <- X_test[, common_vars, drop=FALSE]
    y_pred <- predict(fit, newdata=data.frame(X_test_sub), type="response")
    
    y_pred_class <- ifelse(y_pred > 0.5, 1, 0)
    tp <- sum(y_pred_class==1 & y_test==1)
    tn <- sum(y_pred_class==0 & y_test==0)
    fp <- sum(y_pred_class==1 & y_test==0)
    fn <- sum(y_pred_class==0 & y_test==1)
    accuracy <- (tp+tn)/length(y_test)
    sensitivity <- ifelse((tp+fn)==0, NA, tp/(tp+fn))
    specificity <- ifelse((tn+fp)==0, NA, tn/(tn+fp))
    
    
    data.frame(model=paste(common_vars, collapse = " + "), accuracy, sensitivity, specificity, Tp=tp, Tn=tn, Fp=fp, Fn=fn)
  })
  
  perf_df <- bind_rows(perf_list)
  kable(perf_df, caption = "Test-set Performance for Plausible Models", format = "html")

} else {
  message("No plausible models available for evaluation.")
}
```

    

# 4. Summary and Interpretation

This report demonstrates a complete workflow for multi-path stepwise selection:

 - Multi-path stepwise selection generates a forest of candidate models through parallel exploration of the model space, moving beyond traditional single-path methods.
 - Stability estimation identifies consistently selected variables across bootstrap resamples, providing robustness to data sampling variations.
 - Plausible model selection balances predictive performance (via AIC with Delta threshold) and stability (via average stability with tau threshold), selecting models that perform well and are consistently identified.
 - Jaccard deduplication removes near-duplicate models with high variable overlap, ensuring diverse candidate sets for interpretation.
 - Comprehensive evaluation includes both training metrics (AIC, stability) and test-set performance (accuracy, sensitivity, specificity).

## Key Findings

For linear regression (simulated data):

 - The method correctly identified the true signal variables (x1, x2, x5) with high stability scores.
 - Variable x1 showed the highest stability (69.6%), consistent with its large coefficient magnitude.

For logistic regression (Breast Cancer data):

 - Cell.size, Bare.nuclei, and Cl.thickness emerged as the most stable predictors.
 - The top plausible models achieved excellent test performance (>97% accuracy), with the best model reaching 99.27% accuracy.
 - Including quadratic and interaction terms expanded the model space, with several interaction terms appearing in top models.

## Practical Implications

The same workflow can be applied to various datasets for both linear (Gaussian) and logistic (Binomial) regression modeling. This approach provides several advantages over traditional stepwise selection:

 - Robustness: By considering multiple paths and stability, the method is less sensitive to random variations in the data.
 - Transparency: All candidate models are explicitly tracked and evaluated.
 - Interpretability: Stability scores help distinguish consistently important variables from those selected by chance.
 - Flexibility: The framework accommodates both linear and generalized linear models with various feature engineering options.

The balance between model performance and stability ensures that selected models are both predictive and reliable, making this approach suitable for both exploratory analysis and confirmatory modeling in applied research.
